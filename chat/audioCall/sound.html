<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Test Speech Synthesis</title>
</head>
<body>
    <script src="https://code.responsivevoice.org/responsivevoice.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>
    <button id="startButton">Start Conversation (Voice)</button>    
    <div id="chat-box"></div>
    <script>
        const OLLAMA_ENDPOINT = 'http://127.0.0.1:11434'; // Replace with your Ollama API endpoint
       const startButton = document.getElementById('startButton');
       const chatBox = document.getElementById('chat-box');

       let recognition;
        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
        if (!SpeechRecognition) {
            alert("Speech Recognition API is not supported by your browser.");
        }

        recognition = new SpeechRecognition();
        recognition.continuous = true;
        recognition.lang = 'en-US';
        recognition.interimResults = false;

        recognition.onstart = function() {
            console.log('Speech recognition started');
        };

        recognition.onerror = function(event) {
            console.error('Speech recognition error:', event.error);
        };

        recognition.onresult = async function(event) {
            const transcript = event.results[event.resultIndex][0].transcript;
            console.log("User said: ", transcript);
            appendMessage('You: ' + transcript);
            await generateStreamingResponse('llama3.2:3b', transcript, chatBox);
        };

        startButton.addEventListener('click', () => {
            recognition.start();
        });


        function appendMessage(message) {
            chatBox.innerHTML += `<p>${message}</p>`;
            chatBox.scrollTop = chatBox.scrollHeight; // Scroll to bottom
        }

        async function generateStreamingResponse(model, prompt, messageDiv) {
            let fullPrompt = prompt;
            let context = '';

            if (this.documents && this.documents.size > 0) {
                context += 'Here are the relevant documents:\n\n';
                this.documents.forEach((content, filename) => {
                    context += `File: ${filename}\n${content}\n\n`;
                });
            }

            if (this.webpages && this.webpages.size > 0) {
                context += 'Here are the relevant webpages:\n\n';
                this.webpages.forEach((content, url) => {
                    context += `URL: ${url}\nContent:\n${content}\n\n`;
                });
            }

            if (context) {
                fullPrompt = context + 'Based on this information, please respond to: ' + prompt;
            }

            try {
                const response = await fetch(`${OLLAMA_ENDPOINT}/api/generate`, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ model, prompt: fullPrompt })
                });

                if (!response.ok) {
                    throw new Error('Failed to generate response');
                }

                const reader = response.body.getReader();
                const contentDiv = messageDiv.querySelector('.message-content') || messageDiv;
                let fullResponse = '';
                let currentMarkdown = '';

                while (true) {
                    const { done, value } = await reader.read();
                    if (done) break;

                    const chunk = new TextDecoder().decode(value);
                    const lines = chunk.split('\n');

                    for (const line of lines) {
                        if (line.trim() === '') continue;

                        try {
                            const data = JSON.parse(line);
                            fullResponse += data.response;
                            currentMarkdown = marked.parse(fullResponse);
                            contentDiv.innerHTML = currentMarkdown;

                            // Apply syntax highlighting to any code blocks
                            contentDiv.querySelectorAll('pre code').forEach((block) => {
                                hljs.highlightBlock(block);
                            });

                            // Auto-scroll to bottom
                            messageDiv.scrollTop = messageDiv.scrollHeight;
                        } catch (e) {
                            console.error('Error parsing JSON:', e);
                        }
                    }
                }

                // Check the response before passing to text-to-speech
                console.log("Ollama response text:", fullResponse);
                appendMessage('Ollama: ' + fullResponse);
                // Finally, speak the full response
                if (fullResponse.trim() !== "") {
                    speakText(fullResponse);
                } else {
                    console.warn("Received empty response from Ollama API.");
                }

            } catch (error) {
                console.error('Error with streaming response:', error);
                appendMessage('Ollama: Sorry, I couldn\'t process your request.');
            }
        }        

        function speakText(text) {
            const speechSpeed=[0.8, 0.9, 1.0, 1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9, 2.0, 2.1, 2.2, 2.3, 2.4, 2.5, 2.6, 2.7, 2.8, 2.9, 3.0];
            // responsiveVoice.speak(text, "US English Male", {rate: speechSpeed[2]});
            speakText_offline(text);

            // responsiveVoice.speak(text, "Google हिन्दी", {rate: 0.9});    
            // window.speechSynthesis.getVoices().map(voice => voice.name);        
        }

        function speakText_offline(text) {
            console.log("Speaking text:", text);
            
            // Only trigger speech if it's user-activated
            const synth = window.speechSynthesis;

            // Ensure there's valid text to speak
            if (text.trim() === "") {
                console.warn("No text to speak");
                return;
            }

            // Create an utterance
            const utterance = new SpeechSynthesisUtterance(text);

            // Wait for voices to be loaded
            const voicesChanged = () => {
                const voices = synth.getVoices();
                console.log("Available voices:", voices);

                // Set the voice to the desired one (e.g., Google US English)
                utterance.voice = voices.find(voice => voice.name === 'Google US English') || voices[0]; // Default to the first available voice

                // Handle speech end event
                utterance.onend = function() {
                    console.log("Speech finished.");
                };
                console.log("utterance utterance:", utterance);
                // Speak the text
                synth.speak(utterance);

                // Remove the event listener after it's triggered
                synth.removeEventListener('voiceschanged', voicesChanged);
            };

            // Add event listener to detect when voices are available
            if (synth.onvoiceschanged !== undefined) {
                synth.addEventListener('voiceschanged', voicesChanged);
            } else {
                voicesChanged(); // If voices are already loaded
            }
        }
    </script>
</body>
</html>
